# Поиск токсичных комментариев

## Задача
Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

**Цель:** научить модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.
Необходимо построить модель со значением метрики качества F1 не меньше 0.75.

Прект был выполнен в Google Colab на GPU
## Библиотеки
pandas, numpy, matplotlib, seaborn, sklearn, time, re, ntlk, warnings, pytorch_transformers, io, torch, keras

## Этапы проекта
1. Загрузка данных.
2. Подготовка данных и обучение моедли линейной регрессии.
- токкенизация и лемматизация текста с помощью Wordnet Lemmatizer с учетом pos_tag и удаление стоп-слов
- векторизация слов методом TfidfVectorize
- обучение моедли с подбором гиперпараметров с помощью GridSearchCV
3. Подготовка данных и обучение моедли BERT.
- добавление специальных токены [CLS] и [SEP] и выполнение токенизации встроенным методом модели BERT
- паддинг и преобразование данных в pytorch тензоры
- деление данных по батчам произвольно с помощью RandomSampler
- тюнинг предобученного BertForSequenceClassification с оберткой в pipeline и подбором оптимальных гиперпарметров
4. Сравнение полученных моделями результатов. Выбор оптимальной модели.

## Вывод
Подготовлена модель BERT для поиска токсичных комментариев, ее результат на тестовой выборке - f1 = 0,83.
